{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "############# 질의응답, 모델, 임베딩\n",
    "#############\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.retrievers.document_compressors import EmbeddingsFilter\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.llms import LlamaCpp\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "Answer: Let's work this out in a step by step way to be sure we have the right answer.\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "\n",
    "llm = LlamaCpp(\n",
    "\t# model_path: 로컬머신에 다운로드 받은 모델의 위치\n",
    "    model_path=\"C:\\llama_test\\llama-2-7b-chat.Q4_K_M.gguf\",\n",
    "    temperature=0.0,\n",
    "    top_p=1,\n",
    "    max_tokens=8192,\n",
    "    verbose=True,\n",
    "    # n_ctx: 모델이 한 번에 처리할 수 있는 최대 컨텍스트 길이\n",
    "    n_ctx=4096 \n",
    ")\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"intfloat/multilingual-e5-large\")\n",
    "\n",
    "###### 처음 저장할때\n",
    "# vectordb = Chroma.from_documents(texts,embedding,persist_directory=\"C:/startcoding_vs/test_venv/gg\")\n",
    "\n",
    "vectordb = Chroma(persist_directory=\"C:/startcoding_vs/test_venv/gg\", embedding_function=embedding)\n",
    "# print(\"chromadb에 저장\")\n",
    "\n",
    "\n",
    "##### 파파고 api\n",
    "import requests\n",
    "import json\n",
    "\n",
    "### api key\n",
    "CLIENT_ID, CLIENT_SECRET = '발급받은 ID', '발급받은 Secret'\n",
    "\n",
    "## 질문\n",
    "text = '김종원 교수 수업 하나만 알려줘'\n",
    "\n",
    "url = 'https://openapi.naver.com/v1/papago/n2mt'\n",
    "\n",
    "## 헤더\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'X-Naver-Client-Id': CLIENT_ID,\n",
    "    'X-Naver-Client-Secret': CLIENT_SECRET\n",
    "}\n",
    "\n",
    "## ko -> en\n",
    "data = {'source': 'ko', 'target': 'en', 'text': text}\n",
    "\n",
    "res = requests.post(url, json.dumps(data), headers=headers)\n",
    "\n",
    "en_text = res.json()['message']['result']['translatedText']\n",
    "\n",
    "print('question : ' + text )\n",
    "print('')\n",
    "print('question : ' + en_text)\n",
    "\n",
    "docs = vectordb.similarity_search(en_text)\n",
    "# print(docs)\n",
    "\n",
    "prompt= en_text\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# 유사도 0.7로 임베딩 필터를 저장\n",
    "# 유사도에 맞추어 대상이 되는 텍스트를 임베딩함\n",
    "embeddings_filter = EmbeddingsFilter(\n",
    "    embeddings=embedding, \n",
    "    similarity_threshold=0.70\n",
    ")\n",
    "\n",
    "# 압축 검색기 생성\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "\t# embeddings_filter 설정\n",
    "    base_compressor=embeddings_filter, \n",
    "    # retriever 를 호출하여 검색쿼리와 유사한 텍스트를 찾음\n",
    "    base_retriever=vectordb.as_retriever()\n",
    ")\n",
    "\n",
    "# RetrievalQA 클래스의 from_chain_type이라는 클래스 메서드를 호출하여 질의응답 객체를 생성\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=compression_retriever)\n",
    "response = qa.run(prompt)\n",
    "\n",
    "### 파파고 api\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'X-Naver-Client-Id': CLIENT_ID,\n",
    "    'X-Naver-Client-Secret': CLIENT_SECRET\n",
    "}\n",
    "\n",
    "## en -> ko\n",
    "data2 = {'source': 'en', 'target': 'ko', 'text': response}\n",
    "\n",
    "res = requests.post(url, json.dumps(data2), headers=headers)\n",
    "\n",
    "result_text = res.json()['message']['result']['translatedText']\n",
    "\n",
    "print('response : ' + response)\n",
    "# print('____________파파고 번역 후_________________')\n",
    "print('')\n",
    "print('response : ' + result_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "################## PDF파일\n",
    "##################\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "## 불러오기\n",
    "loader = PyPDFLoader('C:/startcoding_vs/test_venv/hh/2010~2023학년도 교양교육과정 이수기준 안내.pdf')\n",
    "\n",
    "documents = loader.load()\n",
    "documents[0].page_content[:200]\n",
    "\n",
    "## 텍스트 나누기\n",
    "text_splitter = CharacterTextSplitter(\n",
    "\tchunk_size=100, \n",
    "    chunk_overlap=0\n",
    "    )\n",
    "\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "## 임베딩\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"intfloat/multilingual-e5-large\")\n",
    "\n",
    "## 저장\n",
    "vectordb = Chroma.from_documents(texts,embedding,persist_directory=\"C:/startcoding_vs/test_venv/gg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "################## CSV파일\n",
    "##################\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "## 불러오기\n",
    "loader = CSVLoader('C:/startcoding_vs/test_venv/hh/의료ㆍIT학과 이수기준.csv')\n",
    "\n",
    "documents = loader.load()\n",
    "documents[0].page_content[:200]\n",
    "\n",
    "## 텍스트 나누기\n",
    "text_splitter = CharacterTextSplitter(\n",
    "\tchunk_size=100, \n",
    "    chunk_overlap=0\n",
    "    )\n",
    "\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "## 임베딩\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"intfloat/multilingual-e5-large\")\n",
    "\n",
    "## 저장\n",
    "vectordb = Chroma.from_documents(texts,embedding,persist_directory=\"C:/startcoding_vs/test_venv/gg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
